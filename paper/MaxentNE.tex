\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{Name Entity Tagger using Maxent Classifier}

\author{Xihua Yang\\
Courant Institute of Mathematical Sciences\\
251 Mercer St, New York, NY 10012\\
{\tt\small xy644@nyu.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
}

\maketitle
%\thispagestyle{empty}
\lstset{basicstyle=\ttfamily,
  breaklines=true}
%%%%%%%%% ABSTRACT
\begin{abstract}
Present a name entity tagger built with maximum entropy classifier. Different combinations of features are tested and compared by performance on CoNLL-2002\cite{CoNLL} shared task corpus, which includes a Spanish dataset and a Dutch dataset. The classifier obtained $73.60\%$ $F_1-$measure on Spanish dataset and $69.26\%$ $F_1-$measure on Dutch dataset.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

\subsection{Objective}
Build a name entity tagger with maximum entropy classifier. The name tagger should be able to recognize the category of each word in CoNLL-2002 dataset.

\subsection{External softwares and web resources}
\begin{itemize}
   \item NLTK 3.0.2\cite{BirdKleinLoper09}
   \item Megam\cite{Megam}
\end{itemize}

\subsection{System feature}
\begin{itemize}
   \item Language: Python 2.6
   \item Dataset: CoNLL-2002 shared task
\end{itemize}

%-------------------------------------------------------------------------
\section{Experiment}

\subsection{Dataset}
The dataset comes from CoNLL-2002 shared task. It contains 4 kinds of name entities, which are Person, Location, Organization and Miscellany, they are labeled as "PER", "LOC", "ORG", and "MISC" respectively. The name entities are tagged using BIO tags in training data, "B" indicates the start of a new name entity, "I" indicates a word that is inside a name entity but not the begin word, and "O" means this word is outside any name entities. For example, the begining word of a Person type name entity will be tagged as "B-PER".
\par The dataset contains training and test data in Spanish and Dutch, Spanish training data has 264715 training samples, and Dutch training data has 202644 training samples.
\par During experiment, the performance of different feature sets are compared base on Spanish dataset. To avoid getting memory overflow and speed up training process, Megam package is used.

\subsection{Previous Work}
According to Tjong's paper\cite{Tjong}, many techniques are adopted for CoNLL-2002 shared task, among which only Malouf\cite{Malouf} used maximum entropy classifier. In Malouf's paper, he reached F1-score of $73.66\%$ on Spanish dataset and $68.08\%$ on Dutch dataset.

\subsection{Features}
\par In previous homework assignment, I have found that using previous word, current word, next word, their POS tags and the combination of these features will result in a good performance, and previous BIO tag is also a good feature, therefore my initial feature set is: 
\begin{lstlisting}
previous word
current wor
next word
previous POS tag
current POS tag
next POS tag
previous word + current word
current word + next word
previous word + current word + next word
previous POS tag + current POS tag + next POS tag
previous BIO tag
\end{lstlisting}
F1-score is $59.93\%$

\par In Nadeau and Sekine's paper\cite{Survey}, they listed a bunch of possible features that could help improving performance of name entity taggers, including case, punctuation, digit, etc. Therefore in second iteration, I also detected whether the word is a title word, whether the word contains a punctuation, and whether it contains a digit but is not a numerical word. Also, the length of word is added as a feature, now the feature set is:
\begin{lstlisting}
previous word
current wor
next word
previous POS tag
current POS tag
next POS tag
previous word + current word
current word + next word
previous word + current word + next word
previous POS tag + current POS tag + next POS tag
previous BIO tag
istitle
punctuation
contain digit
word length
\end{lstlisting}
F1-score is $65.28\%$

\par Refering to Tkachenko and Simanovsky's paper\cite{Explore}, features like prefix and suffix are also useful. Since we don't know the common length of prefix and suffix in Spanish, I have to try different features. Length from 1 to 7 are tried for prefix, and 5 to 1 are tried for suffix. At last, it turned out that prefix with length 6, suffix with length 2 and 1 yielded best performance. The feature set is:
\begin{lstlisting}
previous word
current wor
next word
previous POS tag
current POS tag
next POS tag
previous word + current word
current word + next word
previous word + current word + next word
previous POS tag + current POS tag + next POS tag
previous BIO tag
istitle
punctuation
contain digit
word length
prefix6
suffix2
suffix1
\end{lstlisting}
F1-score is $70.77\%$

\par Now we want to take more feature on the shape of word into consideration. In Nadeau and Sekine's paper, they mentioned that whether the word is upper case or mix case would also help. I did not take whether it is a lower case word as a feature, because that will mess up words like "Apple" and "apple". Now the feature set is:
\begin{lstlisting}
previous word
current wor
next word
previous POS tag
current POS tag
next POS tag
previous word + current word
current word + next word
previous word + current word + next word
previous POS tag + current POS tag + next POS tag
previous BIO tag
istitle
punctuation
contain digit
word length
prefix6
suffix2
suffix1
is upper case
is mix case(not upper case and not lower case and not title)
\end{lstlisting}
F1-score is $72.61\%$

\par Also, we tried to stem the words and add them as features. Current word is more possible to be part of a name entity when previous word is name entity and current word is a noun, we also add a joint feature of current POS and previous BIO tag into feature set. For test set, previous prediction is taken as previous BIO tag. Besides, if adjacent words are title words, current word is likely to be a part of name entity if it is noun. Now the feature set is:
\begin{lstlisting}
previous word
current wor
next word
previous POS tag
current POS tag
next POS tag
previous word + current word
current word + next word
previous word + current word + next word
previous POS tag + current POS tag + next POS tag
previous BIO tag
istitle
punctuation
contain digit
word length
prefix6
suffix2
suffix1
is upper case
is mix case(not upper case and not lower case and not title)
current POS + previous BIO
previous stem
current stem
next stem
previous istitle + next istitle + current pos
\end{lstlisting}
F1-score is $73.06\%$

\par If we also add whether previous word is title word and whether next word is title word, this could also help, because continuous title words could possibly form up a name entity. Now the feature set is:
\begin{lstlisting}
previous word
current wor
next word
previous POS tag
current POS tag
next POS tag
previous word + current word
current word + next word
previous word + current word + next word
previous POS tag + current POS tag + next POS tag
previous BIO tag
istitle
punctuation
contain digit
word length
prefix6
suffix2
suffix1
is upper case
is mix case(not upper case and not lower case and not title)
current POS + previous BIO
previous stem
current stem
next stem
previous istitle + next istitle + current pos
\end{lstlisting}
F1-score is $73.60\%$

\par There are some other features tried but not resulting a good performance. I tried to add the upper case form of current word, lower case form of current word, the joint of previous POS tag and current POS tag, the joint of current POS tag and next POS tag. However, they yielded poorer performance. Their F1-scores are $71.12\%$, $71.49\%$, $68.74\%$ and $70.58\%$ respectively.

\par According to Mao's paper\cite{Global}, we can try to adopt non-local features such as the position of word in sentence. I tried to add the position information into feature set, but this did not perform well on CoNLL-2002, the F1-score is $70.51\%$

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}